# Even though latest ATM is 3,
# sticking wtih 2.1 for the "condition" in "depends_on"
# It was deprecated in version 3
# Check https://docs.docker.com/compose/startup-order/
# 
# Update 2020-12-04: could check
# - https://github.com/elastic/elasticsearch/blob/master/distribution/docker/docker-compose.yml
# - https://github.com/dadoonet/fscrawler/blob/master/contrib/docker-compose-example/docker-compose.yml

version: '2.1'

services:
  imageclassify:
    build:
      context: ${PWD}/image_classify
    volumes:
    - /home/alice/ownCloud/:/home/alice/ownCloud/
    restart: always
    depends_on:
      - deepdetectgpu
  elasticsearch_client:
    build:
      context: ${PWD}/client
      dockerfile: ./Dockerfile
    ports:
        - "1358:1358"
    restart: always
    depends_on:
      - fileserver
  fileserver:
    build:
      context: ${PWD}/file_server
    ports:
      - '3000:3000'
    volumes:
    - /home/alice/ownCloud/:/home/alice/ownCloud/
    restart: always
  # fscrawler service for indexing a folder
  # Also check `fscrawlerrest` service for REST access
  fscrawler:
    build:
      # ubuntu as base image
      context: ${PWD}
      # alpine linux as base image
      # context: ${PWD}/alpine
    volumes:
    #- ${PWD}/test/data/:/usr/share/fscrawler/data/:ro
    - /home/alice/ownCloud/:/usr/share/fscrawler/data/:ro
    - ${PWD}/config/docker-compose:/usr/share/fscrawler/config-mount/docker-compose

    # Despite the python tester having a built-in healthcheck at tests/es_acceptance.py#wait_for_cluster_health
    # Using the dockerfile healthcheck extends this to other services without having to re-code a wait for health status in each
    # Note that this requires docker-compose.yml version 2.1, docker-compose>=1.11, docker>=1.13 
    depends_on:
      # Should be es_init here, but not sure why fscrawler fails to detect it has executed
      # This "depends_on.condition" syntax is deprecated anyway, so not thinking it through
      # es_init:
      elasticsearch1:
        condition: service_healthy
    command:
      - --trace
      - --config_dir
      - /usr/share/fscrawler/config
      - docker-compose
    restart: always
  deepdetectgpu:
    image: jolibrain/deepdetect_gpu
    ports:
      - 3542:8080
    volumes:
      - /home/alice/ownCloud/models/:/opt/models/
      - /home/alice/ownCloud/:/usr/share/fscrawler/data/:ro
    deploy:
      resources:
        reservations:
          devices:
          - capabilities: [gpu]
    restart: always
    depends_on:
      elasticsearch1:
        condition: service_healthy
  elasticsearch1:
    ports:
      - "9200:9200"
    build:
      # build a dockerfile on top of the official elasticsearch docker image hosted at docker.elastic.co
      # It includes healthcheck
      # Check build/elasticsearch/Dockerfile for more details
      context: ${PWD}/build/elasticsearch

    # https://github.com/elastic/elasticsearch/blob/master/distribution/docker/docker-compose.yml#L6
    # https://stackoverflow.com/a/61547317/4126114
    environment:
      - discovery.type=single-node
    restart: always
  # service that serves .travis.yml to make curl calls to elasticsearch1 and fscrawler
  tester:
    build:
      context: ${PWD}/build/tester/
    volumes:
    #- ${PWD}/test/data/:/usr/share/fscrawler/data/:ro
    - /home/alice/ownCloud/:/usr/share/fscrawler/data/:ro

  # worker service that uploads example pipeline
  es_init:
    build:
      context: ${PWD}/build/es_init/
    depends_on:
      elasticsearch1:
        condition: service_healthy
    environment:
      - ES_URL=http://elasticsearch1:9200

# do not need fscrawlerrest
  # cannot name service with underscores
  # https://github.com/dadoonet/fscrawler/issues/474
#  fscrawlerrest:
#    build:
#      context: ${PWD}
      # alpine
      # context: ${PWD}/alpine

#    volumes:
    #- ${PWD}/test/data/:/usr/share/fscrawler/data/:ro
#    - /home/alice/ownCloud/:/usr/share/fscrawler/data/:ro
#    - ${PWD}/config/fscrawler_rest:/usr/share/fscrawler/config-mount/fscrawler_rest
    # check note above in fscrawler.depends_on
#    depends_on:
#      elasticsearch1:
#        condition: service_healthy
#    ports:
#      - "8890:8080"
#    command:
#      - --trace
#      - --config_dir
#      - /usr/share/fscrawler/config
#      - --loop
#      - "0"
#      - --rest
#      - fscrawler_rest
